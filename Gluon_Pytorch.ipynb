{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Eric Steele, Liam Tiemon, Mate Virag\n",
    "### Variant 2 - Analysis and Comparison of Gluon, PyTorch and TensorFlow\n",
    "May 4, 2018  \n",
    "Dr. Kevin Kirby  \n",
    "CSC 494"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation \n",
    "___\n",
    "\n",
    "### Gluon\n",
    "___\n",
    "\n",
    "#### For Mac:\n",
    "1. Go to terminal\n",
    "    * Optional: create a new virtual environment\n",
    "2. Run these commands\n",
    "    * pip install gluon\n",
    "    * pip install mxnet\n",
    "\n",
    "#### For Windows:\n",
    "1. Go to http://landinghub.visualstudio.com/visual-cpp-build-tools and download and install the C++ compiler.\n",
    "2. Go to Anaconda prompt\n",
    "    * Optional: create a new virtual environment\n",
    "3. Run these commands\n",
    "    * pip install gluon\n",
    "    * pip install mxnet\n",
    "    \n",
    "\n",
    "### PyTorch\n",
    "___\n",
    "#### For Mac:\n",
    "1. Go to terminal\n",
    "    * Optional: create a new virtual environment\n",
    "2. Go to PyTorch's website (http://pytorch.org) and specify your desired configuration\n",
    "3. Run the returned pip or conda command to install PyTorch\n",
    "\n",
    "#### For Windows:\n",
    "1. Go to Anaconda prompt\n",
    "    * Optional: create a new virtual environment\n",
    "2. Go to PyTorch's website (http://pytorch.org) and specify your desired configuration\n",
    "3. Run the returned pip or conda command to install PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation \n",
    "\n",
    "---\n",
    "\n",
    "## Gluon\n",
    "\n",
    "* http://gluon.mxnet.io contains most of the information required to get started, had code examples, and good documentation.\n",
    "    * This helped us get our project up and going. Following their tutorial helped us get our CNN started and from there we were able to change it to our liking. \n",
    "* http://mxnet.incubator.apache.org/api/python/index.html contains tutorials and documentation for APIs.\n",
    "    * It's API documentation helped us determine which APIs were needed for layers in our CNN.\n",
    "    \n",
    "## PyTorch\n",
    "\n",
    "* There isn't much PyTorch documentation besides the base documentation from the developers and a few GitHub repositories.\n",
    "* PyTorch's [website](https://pytorch.org/tutorials/index.html) has enough code examples to get you started, but not enough to get you in a good place with a CNN\n",
    "* https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n",
    "    * This GitHub repository was a huge help in getting NkuMyaDevMaker.py up and running with PyTorch's network.\n",
    "* https://github.com/pytorch/examples\n",
    "    * The official PyTorch GitHub repository was useful to implement layer connections, defining the network, making drop out, and how to use the activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ease of Use\n",
    "___\n",
    "\n",
    "## Network\n",
    "\n",
    "___\n",
    "\n",
    "#### Gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9df0ae65593d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#imports necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "#imports necessary\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, ndarray\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the model\n",
    "net = gluon.nn.Sequential()\n",
    "    \n",
    "# Declare hyperparameters\n",
    "convo1_kernels = 20\n",
    "convo1_kernel_size = (5,5)\n",
    "convo2_kernels = 40\n",
    "convo2_kernel_size = (5,5)\n",
    "pooling = 2\n",
    "\n",
    "hidden1_neurons = 20\n",
    "dropout_rate = 0.3\n",
    "hidden2_neurons = 15\n",
    "\n",
    "# Define our network\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Conv2D(channels=convo1_kernels, kernel_size=convo1_kernel_size, use_bias=True, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=pooling, strides=pooling))\n",
    "    net.add(gluon.nn.BatchNorm())\n",
    "    net.add(gluon.nn.Conv2D(channels=convo2_kernels, kernel_size=convo2_kernel_size, use_bias=True, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=pooling, strides=pooling))\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(hidden1_neurons, activation=\"relu\", use_bias=True))\n",
    "    net.add(gluon.nn.Dropout(dropout_rate))\n",
    "    net.add(gluon.nn.Dense(hidden2_neurons, activation=\"relu\", use_bias=True))\n",
    "    net.add(gluon.nn.Dense(1, activation=\"sigmoid\", use_bias=True)) # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a network in Gluon is similar to TensorFlow. It offers the same types of convolutional and dense layers with very similar lists of parameters that can be passed in to them. It also offers features, such as batch normalization, dropout and image flattening just like TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports used\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\"\"\"Class that defines the neural network.\"\"\"\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Defines the layers in the neural network.\"\"\"\n",
    "    def __init__(self, depth, nk, kernel_size, padding, hidden_neurons, nc):\n",
    "        super(Net, self).__init__()\n",
    "        # out_channels defines the number of kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels=depth, out_channels=nk[0], kernel_size=kernel_size, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(in_channels=nk[0], out_channels=nk[1], kernel_size=kernel_size)\n",
    "        #self.conv2_drop = nn.Dropout2d()\n",
    "        # nc is the image size after convolution and pooling\n",
    "        self.fc1 = nn.Linear(nc * nc * nk[1], hidden_neurons[0])\n",
    "        self.fc2 = nn.Linear(hidden_neurons[0], hidden_neurons[1])\n",
    "        # Single value output\n",
    "        self.fc3 = nn.Linear(hidden_neurons[1], 1)\n",
    "\n",
    "    \"\"\"\n",
    "    Defines the connections and the activation functions between layers, pushes the \n",
    "    input patterns through the network and returns the network's output.\n",
    "    \"\"\"\n",
    "    def forward(self, x, pooling):\n",
    "        # Max pooling over a square window with stride of pool size to avoid overlaps\n",
    "        # Activatin functions are specified in this function even for the convolutional layer\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=pooling, stride=pooling)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=pooling, stride=pooling)\n",
    "        #x = F.max_pool2d(F.relu(self.conv2_drop(self.conv2(x))), kernel_size=pooling, stride=pooling)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the size of the flat array for the input of the first dense layer \n",
    "    after the last convolutional layer.\n",
    "    \"\"\"\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # All dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a network in PyTorch is a lot different than in Gluon or TensorFlow because it is a low-level framework compared to the other two frameworks we used. PyTorch requires a class inheriting from torch.nn.Module to be implemented when creating a neural network. This class is generally implemented using three functions that define the network. The \\__init\\__ function defines the layers in the neural network, however, PyTorch defines these layers at a much lower level than TensorFlow or Gluon. For example, PyTorch requires the user to calculate the number of input and output channels for each layer, while TensorFlow and Gluon automatically handled those calculations. Furthermore, PyTorch doesn't allow the user to define the activation function for the layers, instead, it requires the user to push the activations through an activation function manually prior to passing the output as the input of the next layer.  \n",
    "  \n",
    "The forward function defines the activation function between layers and how the layers created in \\__init\\__ are connected to each other. It also implements pooling for the convolutional layers. Furthermore, forward is used to push the input patterns through the network and it returns the output of the NN.  \n",
    "  \n",
    "Finally, the function num_flat_features simply calculates the size of the flat array for the input of the first dense layer after the last convolutional layer.  \n",
    "  \n",
    "Overall, defining a network in PyTorch required a lot more effort and implementation than TensorFlow and Gluon due to the low-level nature of the framework. Since the user is requied to calculate the number of input and output channels for each layer, there is also a higher possibility of errors in the implementation than in TensroFlow or Gluon. Therefore, our conclusion is that TensorFlow and Gluon are more advanced than PyTorch in netowkr implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in features\n",
    "___\n",
    "\n",
    "### Gluon\n",
    "* Batching was automatically done based on a parameter passed into the DataLoader.\n",
    "* Gluon includes a wide variety of pre-implemented basic, convolutional, pooling and activation layers varying from 1D to 3D convolutional layers, dense, dropout and batch normalization layers, as well as the regular activation and pooling layers.\n",
    "* Input channels are automatically computed between layers.\n",
    "* Batch normalization and dropout functions are pre implemented.\n",
    "* Image flattening calculations are automatically done.\n",
    "* You can pass in activation functions, much like TensorFlow.\n",
    "* Parameter specification in methods had a wide range of options.\n",
    "\n",
    "### PyTorch\n",
    "* Low level implementation of features compared to TensorFlow and Gluon, such as defining networks and activation functions between layers, as well as the variety of layers offered. For example, PyTorch doesn't offer a pre-implemented batch normalization layer like TensorFlow and Gluon, and defining a dropout layer is also more complicated than in the other two frameworks.\n",
    "* Batching was automatically done based on a parameter passed into the DataLoader.\n",
    "\n",
    "## Implemented features\n",
    "___\n",
    "\n",
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Accuracy function for a two-class classifier. Receieves real numbers where one class\n",
    "is associated with 0.0 and the other with 1.0. A prediction within 0.33 of the\n",
    "label is considered a correct result. The function returns the number of\n",
    "correct classifications across a batch of predictions and labels.\n",
    "\"\"\"\n",
    "def accuracy(predictions, labels):\n",
    "    # Convert mxnet NDArrays to numpy NDArrays\n",
    "    pred = predictions.asnumpy()[:,0]\n",
    "    lab = labels.asnumpy()[:,0]\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if abs(pred[i] - lab[i]) < 0.33:\n",
    "            correct += 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gluon and PyTorch\n",
    "When attempting to design our own network in Gluon, we initially ran into difficulty with the accuracy function. The built-in version mx.metric.Accuracy is intended for use with one-hot outputs, but we designed our network to use a single output to match the design of the TensorFlow network from HW4. This discrepancy caused our result to consistently be 50% accuracy. Once we identified this issue we wrote our own accuracy function to match the formula used in TfCnn-MyaDev_For_HW4.py, we identified that the networks were in fact learning. We were able to use this function with both Gluon and PyTorch.\n",
    "\n",
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "class MyaDevDataset(mx.gluon.data.Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X                  # NkuMyaDevMaker images\n",
    "        self.Y = Y                  # NkuMyaDevMaker labels\n",
    "        self.transform = transform  # Transformation function (optional)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = (self.X[idx], self.Y[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gluon and PyTorch\n",
    "We initially tried to use Numpy arrays to pass our training and test images to the DataLoader class. We had difficulty identifying the correct shape for that array and elected to write a version of the Dataset class instead. Dataset is very straightforward. The data can be passed to the \\__init\\__ in any form, the \\__len\\__ function returns the number of elements in the dataset, and the \\__getitem\\__ function returns a single element by index (optionally with a transformation applied).\n",
    "\n",
    "This Dataset is then passed to the DataLoader class along with a batch size. The DataLoader is iterable and handles minibatching, returning tuples of data and labels from the Dataset, split into the specified batch size.\n",
    "\n",
    "#### PyTorch\n",
    "* A class had to be created in order to specify connections between layers and hand made calculations had to be done when inputted into a flatten or max pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional implementations\n",
    "#### Gluon and PyTorch\n",
    "When using both of these frameworks, we encountered the problem that they are not using Numpy arrays, instead they have their own specific implemented tensors and objects. This proved to be a problem when we needed to use Numpy arrays, such as when printing the test images. As a solution, we were able to convert these tensors into Numpy arrays and use those to print images, just like in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(a):\n",
    "    img = a.asnumpy() # Convert to Numpy array\n",
    "    plt.imshow(img[:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Results\n",
    "\n",
    "## Reimplementing TensorFlow Network\n",
    "### Gluon\n",
    "\n",
    "Running a Gluon implementation of the network from TfCnn-MyaDev_For_HW4.py gave results consistently around 95% accuracy with the default hyperparameters provided in the file. This is roughly consistent with the results of running the network in TensorFlow.  \n",
    "  \n",
    "This Gluon implementation can be run in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e0a81ef209e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mProject_Steele_Virag_Tiemon_Gluon_Reimplement\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\Project_Steele_Virag_Tiemon_Gluon_Reimplement.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import Project_Steele_Virag_Tiemon_Gluon_Reimplement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "The PyTorch implementation of the TfCnn-MyaDev_For_HW4.py network got around 94% accuracy when successful, but approximately one fifth of the time the network does not learn and finishes with 50% accuracy. We suspect that this fluctuation in accuracy happens due to the random initialization of weights when building the network, however, we found it interesting that it only occurred in the PyTorch framework and not in either of the other frameworks. It also gave us the impression that the PyTorch framework may not be as advanced as TensorFlow and Gluon.  \n",
    "  \n",
    "This PyTorch implementation can be run in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training set...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-800a3b9c0979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mProject_Steele_Virag_Tiemon_Pytorch_Reimplement\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpytorch_reimplement\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\Project_Steele_Virag_Tiemon_Pytorch_Reimplement.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy: {}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtsset_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\Project_Steele_Virag_Tiemon_Pytorch_Reimplement.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m# Use NkuMyaDevMaker to generate images, then format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakeDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrset_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;31m# For convolutional neural nets, we want 2d single plane images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mXtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\NkuMyaDevMaker.py\u001b[0m in \u001b[0;36mmakeDataSet\u001b[1;34m(n, numExamples, training)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mmyanmar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# flip a coin: myanmar or devanagari?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmyanmar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeCharImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMYANMAR_FONT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMYANMAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeCharImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVANAGARI_FONT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVANAGARI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\NkuMyaDevMaker.py\u001b[0m in \u001b[0;36mmakeCharImage\u001b[1;34m(imageSize, fontName, codePoint)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mmaxSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.85\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mfontSize\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mfont_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_height\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mttf_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "import Project_Steele_Virag_Tiemon_Pytorch_Reimplement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing New Networks\n",
    "### Gluon\n",
    "\n",
    "For our own network design in Gluon, we initially tried using SGD as our training algorithm and Mean Squared Error for loss. This was effective but took a long time to produce results. In an effort to make the network learn more quickly, we added a batch normalization layer, second convolution layer, dropout layer, and a second hidden layer. There was some improvement, but training was still slow. We then tried to use the Adam optimizer for our training algorithm instead and found that it trained very quickly, hitting its accuracy threshold and stopping almost immediately. We changed the network to run for the maximum number of epochs and found that rather than overfitting the network, it consistently hit accuracy ratios of above 98%.  \n",
    "  \n",
    "This Gluon implementation can be run in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-55e966385626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mProject_Steele_Virag_Tiemon_Gluon_Redesign\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\Project_Steele_Virag_Tiemon_Gluon_Redesign.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import Project_Steele_Virag_Tiemon_Gluon_Redesign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "In PyTorch, we started with Adam as the optimizer for the training algorithm. However, we began with Mean Absolute Error, mistakenly thinking that PyTorch did not offer Mean Squared Error because the PyTorch version of that function was named differently than in Gluon. Once we identified this, we switched to MSE and got significantly better results. We also gradually increased the training set size which also helped, and changed our network design to include another convolutional and dense layer just like in our Gluon implementation since it has proven to increase the network's accuracy. However, it was interesting that adding a dropout layer actually slightly decreased the network's accuracy, which is the opposite of what happened in the Gluon implementation. Overall, our final results achieved around 97% accuracy, although that rate fluctuated more than that of our Gluon network.\n",
    "\n",
    "Across both the existing networks and our designs, PyTorch routinely had less reliable and consistent results than Gluon.  \n",
    "  \n",
    "This PyTorch implementation can be run in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training set...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8bd1b371e783>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mProject_Steele_Virag_Tiemon_Pytorch_Redesign\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\Project_Steele_Virag_Tiemon_Pytorch_Redesign.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy: {}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtsset_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\Project_Steele_Virag_Tiemon_Pytorch_Redesign.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;31m# Use NkuMyaDevMaker to generate images, then format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakeDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrset_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;31m# For convolutional neural nets, we want 2d single plane images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mXtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\NkuMyaDevMaker.py\u001b[0m in \u001b[0;36mmakeDataSet\u001b[1;34m(n, numExamples, training)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mmyanmar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# flip a coin: myanmar or devanagari?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmyanmar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeCharImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMYANMAR_FONT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMYANMAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeCharImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVANAGARI_FONT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVANAGARI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SpyderProjects\\Final Project\\CSC-494-Deep-Learning\\NkuMyaDevMaker.py\u001b[0m in \u001b[0;36mmakeCharImage\u001b[1;34m(imageSize, fontName, codePoint)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mmaxSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.85\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mfontSize\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mfont_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_height\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mttf_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "import Project_Steele_Virag_Tiemon_Pytorch_Redesign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "After working with both of these frameworks, we concluded that Gluon is a powerful and easy-to-use framework that could potentially compete with TensorFlow in the future since it offers the same features and tools, and produces consistent results that are very similar to TensorFlow's. On the other hand, we found that working with PyTorch requires the implementation of additional classes and features that are already pre-implemented in TensorFlow and Gluon, and it also produces less consistent and accurate results. Therefore, our conclusion is that the PyTorch framework has to improve in its consistency and accuracy, while it also has to provide more built-in features and require less complicated implementations of neural network layers in order to compete with TensorFlow and Gluon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
